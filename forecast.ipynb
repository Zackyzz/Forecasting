{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"forecasting_test.csv\")\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "The last column represents the residence size, but we already got this information based on the hhsize columns, and since a lot of rows are missing we can drop it.\n",
    "We got 6 hhsize and 8 income columns which are being one-hot-encoded. To handle easier the data for now we can undo this encoding.\n",
    "Exactly 2150 rows are null, simultaneously, for zipcode, mozip, children, income and owner - which may happen when those may belong to a similar category.\n",
    "The 2009 (luse1-6) missing values are always missing as a group. It doesn't happen for a single month of a house, therefore filling the data backward/forward may not be optimal.\n",
    "We got luse1-6 which are just lusage but for the year 2009, but in the same time we got the lusage for 2010 and 2011 as rows (so we should either move them all as rows or make new columns per a hh).\n",
    "\"\"\"\n",
    "\n",
    "df = df.drop(columns=[\"size\"])\n",
    "\n",
    "# Merge the income columns into a single one - where the values here will be from 2 to 9\n",
    "# e.g. if the value is 5 then it's like we had income5=1 and the other income columns =0\n",
    "df['income'] = df.loc[:,\"income2\":\"income9\"].idxmax(axis=1).str[-1]\n",
    "df['income'] = pd.to_numeric(df['income'], errors='coerce')\n",
    "df = df.drop(columns=df.loc[:,\"income2\":\"income9\"])\n",
    "\n",
    "# Merge the hhsize columns into a single one - where the values here will be from 2 to 6\n",
    "df = df.rename(columns={'hhsize5plus': 'hhsize6'})\n",
    "df['hhsize'] = df.loc[:,\"hhsize2\":\"hhsize6\"].idxmax(axis=1).str[-1]\n",
    "df['hhsize'] = pd.to_numeric(df['hhsize'], errors='coerce')\n",
    "df = df.drop(columns=df.loc[:,\"hhsize2\":\"hhsize6\"])\n",
    "\n",
    "# Fill the missing values from static features\n",
    "# It appears that all the columns where exactly 2150 rows got null values belong to hhsize5plus (hhsize=6)\n",
    "missing_data_rows = df[df[['zipcode', 'mozip', 'children', 'income', 'owner']].isnull().any(axis=1)]\n",
    "print(sum(missing_data_rows['hhsize'] != 6))\n",
    "\n",
    "# So we'll fill the data with the most frequent value of each column (with the condition that this value belong to hhsize=6)\n",
    "df.loc[df['hhsize'] == 6, 'zipcode'] = df.loc[df['hhsize'] == 6, 'zipcode'].fillna(df[df['hhsize'] == 6]['zipcode'].mode()[0])\n",
    "df.loc[df['hhsize'] == 6, 'mozip'] = df.loc[df['hhsize'] == 6, 'mozip'].fillna(df[df['hhsize'] == 6]['mozip'].mode()[0])\n",
    "df.loc[df['hhsize'] == 6, 'children'] = df.loc[df['hhsize'] == 6, 'children'].fillna(df[df['hhsize'] == 6]['children'].mode()[0])\n",
    "df.loc[df['hhsize'] == 6, 'owner'] = df.loc[df['hhsize'] == 6, 'owner'].fillna(df[df['hhsize'] == 6]['owner'].mode()[0])\n",
    "df.loc[df['hhsize'] == 6, 'income'] = df.loc[df['hhsize'] == 6, 'income'].fillna(df[df['hhsize'] == 6]['income'].mode()[0])\n",
    "\n",
    "# Fill the missing lusage values (from 2009)\n",
    "# A quick inspection shows that the lusage values dont have an immediate visual correlation like above, so we'll impute based on other features\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "\n",
    "# lusage was added to give more information to the imputer, but we should experiment with other columns as well\n",
    "columns_for_imputation = ['luse1', 'luse2', 'luse3', 'luse4', 'luse5', 'luse6', 'lusage']\n",
    "imputer = IterativeImputer(max_iter=16, random_state=6)\n",
    "df_imputed = pd.DataFrame(imputer.fit_transform(df[columns_for_imputation]), columns=columns_for_imputation)\n",
    "\n",
    "df[['luse1', 'luse2', 'luse3', 'luse4', 'luse5', 'luse6']] = df_imputed[['luse1', 'luse2', 'luse3', 'luse4', 'luse5', 'luse6']]\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We'll try to train an LSTM forecast the last month lusage value, based on the previous ones\n",
    "# More exactly, we'll train the LSTM based on data from 2009 (6 months), 2010 (5 months) and 2011 (4 months)\n",
    "# The target will be the last month of 2011.. In case we need to forecast future months, then we'll just\n",
    "# predict the last month, shift data by one to the left and insert the new predicted month - then predict again\n",
    "\n",
    "# Here we'll reshape the df so that we have a column with all lusage value\n",
    "reshaped_data = []\n",
    "grouped = df.groupby('hh_id')\n",
    "additional_features = ['zipcode', 'mozip', 'children', 'owner', 'income', 'hhsize']\n",
    "\n",
    "for _, group in grouped:\n",
    "    lusage_2009 = group.iloc[0][['luse1', 'luse2', 'luse3', 'luse4', 'luse5', 'luse6']].values\n",
    "    lusage_2010_2011 = group['lusage'].values\n",
    "    other_features = group.iloc[0][additional_features].values\n",
    "    reshaped_data.append(list(other_features) + [list(lusage_2009) + list(lusage_2010_2011)])\n",
    "\n",
    "reshaped_df = pd.DataFrame(reshaped_data, columns=additional_features+['lusage_sequence'])\n",
    "reshaped_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# As mentioned above, we'll use the first 15 months to train (X_lusage) and the last month being the target (y)\n",
    "# The static featurs (X_static), as they're the same we'll be fed separately in the model\n",
    "X_static = reshaped_df[['zipcode', 'mozip', 'children', 'owner', 'income', 'hhsize']].values\n",
    "X_lusage_full = np.array(reshaped_df['lusage_sequence'].tolist())\n",
    "X_lusage = X_lusage_full[:, :-1]\n",
    "y = X_lusage_full[:, -1]\n",
    "\n",
    "# Normalizing the data\n",
    "scaler_static = MinMaxScaler()\n",
    "scaler_lusage = MinMaxScaler()\n",
    "scaler_y = MinMaxScaler()\n",
    "\n",
    "X_static_scaled = scaler_static.fit_transform(X_static)\n",
    "X_lusage_scaled = np.array([scaler_lusage.fit_transform(x.reshape(-1, 1)).flatten() for x in X_lusage])\n",
    "y_scaled = scaler_y.fit_transform(y.reshape(-1, 1))\n",
    "\n",
    "X_train_static, X_test_static, X_train_lusage, X_test_lusage, y_train, y_test = train_test_split(\n",
    "    X_static_scaled, X_lusage_scaled, y_scaled, test_size=0.2, random_state=6)\n",
    "\n",
    "# LSTM expects a tensor, so we'll reshape to have (nr_samples = households, timesteps = 15months, features = 1 lusage)\n",
    "X_train_lusage = X_train_lusage.reshape((X_train_lusage.shape[0], X_train_lusage.shape[1], 1))\n",
    "X_test_lusage = X_test_lusage.reshape((X_test_lusage.shape[0], X_test_lusage.shape[1], 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Input, LSTM, Dense, Concatenate\n",
    "from keras.models import Model\n",
    "\n",
    "lusage_input = Input(shape=(X_train_lusage.shape[1], 1)) # 15 timesteps per household with 1 feature\n",
    "static_input = Input(shape=(6,)) # 6 static featurs\n",
    "\n",
    "lstm_output = LSTM(64)(lusage_input)\n",
    "static_output = Dense(16, activation='relu')(static_input)\n",
    "combined = Concatenate()([lstm_output, static_output])\n",
    "output = Dense(1)(combined) # predicting only the last month value, based on both static and lusage data\n",
    "\n",
    "model = Model(inputs=[lusage_input, static_input], outputs=output)\n",
    "model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "history = model.fit([X_train_lusage, X_train_static], y_train,  epochs=50, batch_size=16, validation_data=([X_test_lusage, X_test_static], y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_scaled = model.predict([X_test_lusage, X_test_static])\n",
    "y_pred = scaler_y.inverse_transform(y_pred_scaled)\n",
    "y_test_original = scaler_y.inverse_transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(6, 4))\n",
    "plt.plot(y_test_original[100:200], label='Original', marker='o', color='blue')\n",
    "plt.plot(y_pred[100:200], label='Predicted', marker='x', color='red')\n",
    "plt.title('Original vs Predicted LUsage')\n",
    "plt.xlabel('Households')\n",
    "plt.ylabel('LUsage')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's try to also train a new LSTM with new features (such as the trend)\n",
    "# We fill the first 2 nan values with the previous existing ones, and also we dont take into account the 16th month\n",
    "reshaped_df['trend'] = reshaped_df['lusage_sequence'].apply(lambda x: pd.Series(x[:-1]).rolling(window=3).mean().fillna(pd.Series(x)).tolist())\n",
    "X_trend = np.array(reshaped_df['trend'].tolist())\n",
    "\n",
    "scaler_trend = MinMaxScaler()\n",
    "X_trend_scaled = np.array([scaler_lusage.fit_transform(x.reshape(-1, 1)).flatten() for x in X_trend])\n",
    "X_lstm_input = np.stack([X_lusage, X_trend], axis=-1)\n",
    "\n",
    "X_train_static, X_test_static, X_train_lusage, X_test_lusage, y_train, y_test = train_test_split(\n",
    "    X_static_scaled, X_lstm_input, y_scaled, test_size=0.2, random_state=6)\n",
    "\n",
    "# LSTM expects a tensor, so we'll reshape to have (nr_samples = households, timesteps = 15months, features = 2 lusage + trend)\n",
    "X_train_lusage = X_train_lusage.reshape((X_train_lusage.shape[0], X_train_lusage.shape[1], 2))\n",
    "X_test_lusage = X_test_lusage.reshape((X_test_lusage.shape[0], X_test_lusage.shape[1], 2))\n",
    "\n",
    "# New LSTM model (TO-DO: make functions for this as it got really messy)\n",
    "lusage_input = Input(shape=(X_train_lusage.shape[1], 2)) # 15 timesteps per household with 2 features now\n",
    "static_input = Input(shape=(6,)) # 6 static featurs\n",
    "\n",
    "lstm_output = LSTM(64)(lusage_input)\n",
    "static_output = Dense(16, activation='relu')(static_input)\n",
    "combined = Concatenate()([lstm_output, static_output])\n",
    "output = Dense(1)(combined) # predicting only the last month value, based on both static and lusage data\n",
    "\n",
    "model = Model(inputs=[lusage_input, static_input], outputs=output)\n",
    "model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "history = model.fit([X_train_lusage, X_train_static], y_train,  epochs=50, batch_size=16, validation_data=([X_test_lusage, X_test_static], y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_trend = model.predict([X_test_lusage, X_test_static])\n",
    "y_pred_trend = scaler_y.inverse_transform(y_pred_trend)\n",
    "y_test_original = scaler_y.inverse_transform(y_test)\n",
    "\n",
    "plt.figure(figsize=(6, 4))\n",
    "plt.plot(y_test_original[100:200], label='Original', marker='o', color='blue')\n",
    "plt.plot(y_pred_trend[100:200], label='Predicted', marker='x', color='red')\n",
    "plt.title('Original vs Predicted (considering also the trend)')\n",
    "plt.xlabel('Households')\n",
    "plt.ylabel('LUsage')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "# Considering the trend the predictions are much much better, even visually (also loss: 0.0125 vs 0.001)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
